Source Article(s):

# She found her naked pics and sex videos online, and is suing Google. Why 'Our Nudes Not Your Business' case is important

Published Date: Monday September 08, 2025

Women are often victims of online privacy violations. Image Strictly for representational purposes only **Photograph: (Others)**

A woman is suing Google over stolen nude photos and sex videos posted online. The lawsuit demands permanent removal of intimate images and AI-generated deepfakes from search results, highlighting privacy rights and the right to be forgotten. Here is why this case matters.

A woman in Germany realised that her supposedly private nude images and sex videos, stolen from her Google Cloud storage, were made available in Google search results. She tried for months to get them removed. Now, she is suing the big tech giant in what could be a landmark privacy case, titled 'Our Nudes Not Your Business'. This is yet another contest between user privacy and Google surveillance. Here is why it adds up to several issues faced by the Big Tech monopoly.

The woman, referred to in court documents as Laura, is suing Google in Ireland, the European headquarters of the tech giant. For months, she tried to get her intimate photos and sex videos removed from Google search results. The visuals were stolen from her private Google Cloud along with her ID. The content was then posted on porn websites and became easily searchable under her name.

Laura is being supported in the court case by the German non-profit group HateAid. She alleged that more than 2,000 URLs were appearing in Google searches on her images and videos. Some content was initially removed after her complaints.

But it didn't stop there. Now there are AI-generated deepfakes of her too. Laura's intimate content kept resurfacing in Google searches, now along with AI-generated deepfakes, said a report in Germany's DW News.

Laura found that her sex videos and naked pictures were online purely by chance, when searching her name online. The experience was akin to having been raped, she told Der Spiegel newspaper. It left her with post-traumatic stress disorder. She changed her job and relocated.

HateAid is running a campaign alongside the lawsuit titled 'Our nudes are #NotYourBusiness.' Josephine Ballon, the CEO of HateAid, which is covering the legal costs as well as future cost risks in this case, said very few such affected people can actually imagine taking the risk of suing a corporation like Google.

Ballon expects a landmark ruling to determine whether search engines must permanently remove reported images, even if re-uploaded elsewhere. As data protection expert Marit Hansen said, the case builds on the 2014 European Court of Justice ruling that established the right to be forgotten. Under the European Union's General Data Protection Regulation (GDPR), people must have control over how their data is used.

Hansen noted that, while obligations for global search engine providers like Google will arise, the extent of these obligations with regard to images must now be delineated.

But this is a tricky area. Filtering out exact image copies is technically easy, according to Hansen, but altered images, such as cropped or AI-generated visuals, pose a challenge. Reverse image searches used by platforms like Google aren’t always accurate, which could be used by companies to deflect responsibility, she was quoted as saying by DW.

From revenge porn to data stolen from computers, mobile phones or cloud storage apps, women have been particularly affected by the misuse of their intimate visuals, including fake or AI-generated pictures and videos. "These days, all you really need is a LinkedIn profile picture,” Hansen said.

The case highlights the societal scale of the problem and the need for criminalising non-consensual deepfakes, she added, while stressing the mental toll of such incidents.

Without action from the search engines, those affected will have to search for images their whole lives and submit manual removal requests, Hansen noted. This is an incredible psychological burden that "should not exist and doesn't have to exist," she added.

While Laura is possibly a common citizen, the predatory violations of privacy involving or facilitated by big tech giants have not spared even the most famous or wealthy. The cloud storage of private images is a minefield for privacy. The Celebgate scandal and cases in 2014 are examples. Even public figures like Taylor Swift and Italian Prime Minister Giorgia Meloni have been targets of deepfakes.